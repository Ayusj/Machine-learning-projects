{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74eefcf-707e-494e-82ee-cfba2e3140a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f837e290-51ab-4a77-846a-241d29c8260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../notes and data/titanic/train.csv')\n",
    "df = pd.read_excel('../../notes and data/titanic/titanic3.xlsx')\n",
    "test = pd.read_csv('../../notes and data/titanic/test.csv')\n",
    "test = test.drop(columns=['Unnamed: 12','Name','Ticket'])\n",
    "train = train.drop(columns=['Name','Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998286c4-e24a-46fb-8ec2-515a31af006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], )\n"
     ]
    }
   ],
   "source": [
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "train =  train.drop(columns=['Cabin'])\n",
    "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
    "print(train.isnull().sum()[train.isnull().sum() > 0].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9db26f-05f0-41b1-bd3e-64ec0fd5a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1758f926-6518-48c4-8f89-2a0b2552ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=['Survived'])\n",
    "y_train = train['Survived']\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869cc416-6c5e-48d7-a20d-66baf8b8b898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], )\n"
     ]
    }
   ],
   "source": [
    "# test = pd.get_dummies(test, drop_first=True).astype(int)\n",
    "test\n",
    "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
    "test =  test.drop(columns=['Cabin'])\n",
    "test['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n",
    "print(test.isnull().sum()[test.isnull().sum() > 0].to_string())\n",
    "test = pd.get_dummies(test, drop_first=True).astype(int)\n",
    "test\n",
    "x_test = test.drop(columns=['Survived'])\n",
    "y_test = test['Survived']\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c045a416-f95b-4907-8d6b-c9de3e557531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.00439733] [[ 8.60209454e-05 -1.06476403e+00 -3.82059781e-02 -3.13591391e-01\n",
      "  -8.14583824e-02  2.20098100e-03 -2.62141946e+00 -2.81640873e-02\n",
      "  -3.83405552e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(x_train,y_train)\n",
    "b = lr_model.intercept_\n",
    "w = lr_model.coef_\n",
    "print(b,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001c1270-4d57-4803-bc16-b68f4fe2d99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7991021324354658\n",
      "0.937799043062201\n"
     ]
    }
   ],
   "source": [
    "train_score = lr_model.score(x_train, y_train)\n",
    "test_score = lr_model.score(x_test,y_test)\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a813387a-7f7c-4156-8e58-e07e4d891f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)  # Clip z to prevent overflow\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "# Cost function\n",
    "def costFn(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    z = np.dot(x, w) + b\n",
    "    f = sigmoid(z)\n",
    "    f = np.clip(f, 1e-10, 1 - 1e-10)  # Clip values to avoid log(0)\n",
    "    cost = -np.mean(y * np.log(f) + (1 - y) * np.log(1 - f))\n",
    "    return cost\n",
    "\n",
    "# Gradient function\n",
    "def gradientFn(x, y, w, b):\n",
    "    m, n = x.shape\n",
    "    djw = np.zeros((n,))\n",
    "    djb = 0.0\n",
    "    for i in range(m):\n",
    "        z = np.dot(w, x[i]) + b\n",
    "        f = sigmoid(z)\n",
    "        err = f - y[i]\n",
    "        for j in range(n):\n",
    "            djw[j] += err * x[i, j]\n",
    "        djb += err\n",
    "    djw /= m\n",
    "    djb /= m\n",
    "    return djw, djb\n",
    "\n",
    "# Gradient descent function\n",
    "def gradientDecent(x, y, w_in, b_in, alpha, iters):\n",
    "    w = copy.deepcopy(w_in)  # avoid modifying global w within function\n",
    "    b = b_in\n",
    "    for i in range(iters):\n",
    "        djw, djb = gradientFn(x, y, w, b)\n",
    "        w = w- alpha * djw\n",
    "        b -= alpha * djb\n",
    "        if i % math.ceil(iters / 10) == 0:\n",
    "            cost = costFn(x, y, w, b)\n",
    "            print(f\"Iteration {i:4d}: Cost {cost:.4f}\")\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1adbb36-16e3-4b9f-8029-1c4b8e657744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b, threshold):\n",
    "    m = x.shape[0]\n",
    "    predictions = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        z = np.dot(w, x[i]) + b\n",
    "        prob = sigmoid(z)\n",
    "        # Classify as 1 if probability is above the threshold\n",
    "        predictions[i] = 1 if prob >= threshold else 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "232923f5-8c5d-4708-9bc3-41bec60b9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 0.6918\n",
      "Iteration  100: Cost 0.5954\n",
      "Iteration  200: Cost 0.5439\n",
      "Iteration  300: Cost 0.5135\n",
      "Iteration  400: Cost 0.4943\n",
      "Iteration  500: Cost 0.4814\n",
      "Iteration  600: Cost 0.4723\n",
      "Iteration  700: Cost 0.4658\n",
      "Iteration  800: Cost 0.4609\n",
      "Iteration  900: Cost 0.4571\n",
      "Final weights: [ 0.00775397 -0.55660897 -0.25559526 -0.19473987 -0.01937382  0.24072224\n",
      " -0.98992766 -0.01554222 -0.173857  ]\n",
      "Final bias: -0.4721488762658939\n"
     ]
    }
   ],
   "source": [
    "# Initial parameters\n",
    "initial_w = np.zeros_like(x_train[0])  # Shape matches the number of features\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "# alpha = 1.0e-5\n",
    "alpha = 0.01\n",
    "# Run gradient descent\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)  # Don't fit on the test set, only transform\n",
    "\n",
    "# Now use x_train_scaled and x_test_scaled in your gradient descent function\n",
    "w, b = gradientDecent(x_train_scaled, y_train, initial_w, initial_b, alpha, iterations)\n",
    "# w, b = gradientDecent(x_train, y_train, initial_w, initial_b, alpha, iterations)\n",
    "print(\"Final weights:\", w)\n",
    "print(\"Final bias:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2305d5ff-d943-4e5a-95e2-ba964f0f86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred = predict(x_test_scaled, w, b,threshold)\n",
    "y_pred_train = predict(x_train_scaled, w, b,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a92a38a5-51c2-4536-a92c-55f8697c4bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9449760765550239 0.7946127946127947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "print(accuracy,accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31dbf7-7dd2-41d7-aa56-c08de23e0f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987935e-b164-4766-ba80-b8769968a496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
